# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Overview

**claude-mining** extracts contacts and insights from Claude conversation history exports using LLM APIs. Supports both **Gemini** and **Claude** models via a unified CLI.

### Critical Cost Warning

**API costs vary dramatically by model.** For 740 conversations:

| Model | Cost | Contacts Found | Recommendation |
|-------|------|----------------|----------------|
| Gemini 3 Flash | ~$7 | 58 | **Default - best value** |
| Claude Opus | ~$444 | 45 | Expensive, fewer results |

Gemini excels at needle-in-haystack tasks (finding scattered mentions). Always run `--dry-run` first to see cost estimates.

### Privacy Constraint

Scripts only - user data stays private. The `.gitignore` blocks `*.json`, `*export*`, output files, and `private/` directories. **NEVER commit user data.**

## Development Commands

### Setup

```bash
# Gemini (recommended)
pip install google-genai
export GOOGLE_API_KEY="your-key"

# Claude (optional)
pip install anthropic
export ANTHROPIC_API_KEY="your-key"
```

### Running Extraction

```bash
# Preview costs (no API calls)
python scripts/intelligent_contacts.py path/to/export.json --dry-run

# Full extraction with Gemini 3 Flash (default)
python scripts/intelligent_contacts.py path/to/export.json -o output_name

# Test on subset first
python scripts/intelligent_contacts.py path/to/export.json --limit 10

# Specific range
python scripts/intelligent_contacts.py path/to/export.json --start 50 --limit 10

# Use Claude Opus instead
python scripts/intelligent_contacts.py path/to/export.json -m opus
```

### Available Models

```
Gemini: gemini-3-flash (default), gemini-3-pro, gemini-2.5-flash, gemini-2.5-pro, gemini-2.0-flash
Claude: opus, sonnet, haiku
```

## Architecture

### Multi-Provider Design

The script uses a provider abstraction pattern:

```python
MODELS = {
    "gemini-3-flash": ("gemini", "gemini-3-flash-preview"),
    "opus": ("claude", "claude-opus-4-20250514"),
    # ...
}

# Provider detection
provider, client, model_id = get_provider_and_client(args.model)

# Unified dispatcher
contacts = extract_contacts_from_conversation(provider, client, text, ...)
```

Each provider has its own extraction function (`extract_contacts_gemini`, `extract_contacts_claude`) but returns the same format.

### Tool/Function Calling

Uses structured tool calling (not JSON parsing) for zero data loss:

- **Claude**: `tools=[CONTACT_TOOL]` with `block.type == "tool_use"`
- **Gemini**: `genai_types.Tool(function_declarations=[...])` with `part.function_call`

Each contact is a separate tool call - if one fails, others succeed.

### Processing Flow

1. **Load** - `load_claude_export()` normalizes export formats
2. **Filter** - Skip conversations unlikely to contain contacts (regex pre-check)
3. **Extract** - One conversation per API call using tool calling
4. **Checkpoint** - Save progress after each conversation (resume on interrupt)
5. **Deduplicate** - Merge by normalized name
6. **Categorize** - Group by relationship keywords
7. **Output** - `.txt` (human-readable) + `.json` (structured)

### Key Files

- `scripts/intelligent_contacts.py` - Main extraction script with multi-provider support
- `scripts/common.py` - Shared utilities for loading exports
- `scripts/holiday_contacts.py` - Regex fallback (no API needed)

### Adding New Providers

To add a new LLM provider:

1. Add entry to `MODELS` dict with `(provider_name, model_id)` tuple
2. Add cost estimate to `COST_PER_CONV` dict
3. Create `extract_contacts_{provider}()` function matching signature
4. Add case to `get_provider_and_client()` for client initialization
5. Add case to `extract_contacts_from_conversation()` dispatcher

### Gemini Import Pattern

Gemini is an optional dependency:

```python
try:
    from google import genai
    from google.genai import types as genai_types
    GEMINI_AVAILABLE = True
except ImportError:
    GEMINI_AVAILABLE = False
```

Check `GEMINI_AVAILABLE` before using Gemini-specific code.

## Output Files

The script generates two files per run:

- `{output}.txt` - Human-readable report with categories, holiday checklist
- `{output}.json` - Structured data for CRM import/automation

Both are generated by `write_report()` and `write_json()` functions.

## Checkpoint/Resume

Progress saves to `{output}.checkpoint.json` after each conversation. On interrupt:

```bash
# Resume from where you left off
python scripts/intelligent_contacts.py path/to/export.json -o same_output_name
```

The checkpoint contains `processed_ids` and `contacts` arrays.

## Documentation Philosophy

When documenting decisions or changes:

| Document | Purpose | Content |
| -------- | ------- | ------- |
| **README.md** | User-facing | How to use (commands, examples) |
| **CLAUDE.md** | AI-facing | How to modify (architecture, patterns) |
| **docs/adr/** | Decision-facing | WHY we chose this (alternatives, trade-offs) |
| **ROADMAP.md** | Future-facing | What's planned (ideas, not commitments) |

**Prefer ADRs** over bloating README when documenting:

- Algorithm choices (why Jaro-Winkler, not SBERT?)
- Architecture decisions (why tool calling, not JSON parsing?)
- Trade-offs (why human-in-the-loop, not full automation?)

ADRs are permanent records. README should stay scannable.
